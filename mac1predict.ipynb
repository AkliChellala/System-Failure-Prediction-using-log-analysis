{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import model_from_yaml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler            #importing all necessary libraries\n",
    "from datetime import timedelta\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('mac_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "yaml_file = open('model1.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model1.h5\")\n",
    "print(\"Loaded model from disk\")                           #loading pre trained weights\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecastnext(ts):\n",
    "    df['CPU1YBLPVDAKDLWAPP1'] = df['CPU1YBLPVDAKDLWAPP1'].apply(pd.to_datetime)\n",
    "    b1=pd.to_datetime(ts)\n",
    "    a1 = pd.to_datetime(ts) - timedelta(minutes=500)\n",
    "    z=df[(df['CPU1YBLPVDAKDLWAPP1']>a1) & (df['CPU1YBLPVDAKDLWAPP1']<b1)]\n",
    "    se=pd.DataFrame(z.x)\n",
    "    size=se.size+1\n",
    "    a2=[]\n",
    "    x2=[]\n",
    "    size1=size-51                                          \n",
    "    series=se[size1:size]                                     #extract last 50 values from column\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))               \n",
    "    scaled = scaler.fit_transform(series.values)\n",
    "    series = pd.DataFrame(scaled)                             #scaling the values\n",
    "    test_X=series.iloc[:]\n",
    "    test_X=test_X.values\n",
    "    test_X=test_X.reshape(1,50,1)\n",
    "    n_future_preds=20                                    #number of predictions to be made\n",
    "    preds_moving = []                                    # Use this to store the prediction made on each test window\n",
    "    moving_test_window = [test_X[0,:].tolist()]          # Creating the first test window\n",
    "    moving_test_window = np.array(moving_test_window)    # Making it an numpy array\n",
    "    ts=pd.to_datetime(ts)\n",
    "    tsac=ts.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "\n",
    "    for i in range(n_future_preds):\n",
    "        preds_one_step = loaded_model.predict(moving_test_window) # Note that this is already a scaled prediction so no need to rescale this\n",
    "        preds_one_step.reshape(1,1)\n",
    "        preds_one_step = scaler.inverse_transform(preds_one_step)                       #transforming into actual format\n",
    "\n",
    "        preds_moving.append(preds_one_step[0,0]) # get the value from the numpy 2D array and append to predictions\n",
    "        preds_one_step = preds_one_step.reshape(1,1,1) # Reshaping the prediction to 3D array for concatenation with moving test window\n",
    "        moving_test_window = np.concatenate((moving_test_window[:,1:,:], preds_one_step), axis=1) # This is the new moving test window, where the first element from the window has been removed and the prediction  has been appended to the end\n",
    "        ts=pd.to_datetime(ts)+timedelta(minutes=10)\n",
    "        ts1=pd.to_datetime(ts)+timedelta(minutes=10)\n",
    "        a2.append(ts.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        x3=dict(zip(a2,preds_moving))\n",
    "        x4=dict(zip('input',tsac))\n",
    "        lst=[]\n",
    "        lst.append({'input':tsac,'output':x3})\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '2019-01-06 05:10:04',\n",
       "  'output': {'2019-01-06 05:20:04': -83.28951,\n",
       "   '2019-01-06 05:30:04': -292.1135,\n",
       "   '2019-01-06 05:40:04': -509.79755,\n",
       "   '2019-01-06 05:50:04': -723.85156,\n",
       "   '2019-01-06 06:00:04': -931.1221,\n",
       "   '2019-01-06 06:10:04': -1114.4348,\n",
       "   '2019-01-06 06:20:04': -1240.0012,\n",
       "   '2019-01-06 06:30:04': -1278.2535,\n",
       "   '2019-01-06 06:40:04': -1229.6056,\n",
       "   '2019-01-06 06:50:04': -1127.3274,\n",
       "   '2019-01-06 07:00:04': -1008.18225,\n",
       "   '2019-01-06 07:10:04': -897.0384,\n",
       "   '2019-01-06 07:20:04': -805.748,\n",
       "   '2019-01-06 07:30:04': -736.7186,\n",
       "   '2019-01-06 07:40:04': -687.8455,\n",
       "   '2019-01-06 07:50:04': -656.0063,\n",
       "   '2019-01-06 08:00:04': -637.9409,\n",
       "   '2019-01-06 08:10:04': -630.5801,\n",
       "   '2019-01-06 08:20:04': -631.2353,\n",
       "   '2019-01-06 08:30:04': -637.683}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastnext(\"2019-01-06 05:10:04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
